{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"meme.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd=r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23 Upon the termination or expiration ofa Subject Agreement,\n",
      "\n",
      "() Bach Party will immediately cease holding self out as having a commercial relationship\n",
      "with the Other Party in relation to the products andor services covered under such Subject\n",
      "Agreement;\n",
      "\n",
      "(©) Bach Party shall immediatly cease use ofthe Other Party's trademark, service marks,\n",
      "trade names, service names, logos, symbols, and ater product or service designations\n",
      "Pertaining to such Subject Agreement; Further, each party shall retum the confidential\n",
      "‘information tothe other party on tcmination/expiry ofthe agreement.\n",
      "\n",
      "(©) Bach Party shall immediately comply with the requirements set forth in Section 7.7;\n",
      "\n",
      "@\n",
      "\n",
      "Client shall pay ll amounts properly due and payable to Ebix under such Subject\n",
      "‘Agreement up until and through the effetive date of such termination or expietio,\n",
      "\n",
      "(©) wither Party shall have any further tiabilty or obligation to the Other Party pursuant to\n",
      "such Subject Agreement, except as may be otherwise expressly agreed (0 in writing by the\n",
      "Paris,\n",
      "\n",
      "EES & PAYMENT TERMS\n",
      "\n",
      "34\n",
      "\n",
      "32\n",
      "\n",
      "33\n",
      "\n",
      "INDEMNIFICATION\n",
      "\n",
      "4a\n",
      "\n",
      "Fees & Costs. Conditioned upon the prior execution by bath Parties of this Agreement and in\n",
      "consideration of the products and/or services described in a Subject Agreement, Client shall pay Ebix\n",
      "the fees and costs set forth and agreed upon by the Paris in such Subject Agreement. In aditon to\n",
      "Such fes and costs, Client agrees to pay any sles, use, excise andr other taxes (“Sales and Use\n",
      "Taxes”) levied upon ether Party by any government taxing authority as applicable to the Subject\n",
      "Agreement, except for taxes based on Ebin’s income. Sales and Use Taxes as they oeeur wil be added\n",
      "to invoices.\n",
      "\n",
      "ferment, Payment shall be made by Clint whi hy (0) dys folowing receipt of invoice, In\n",
      "the event an invoice isnot paid within the thity $0 day perio, the amount ofthe invoice shal bear “2\n",
      "interest at rate of 1.0% per month. If such rate isin excess ofthe amount permite law, ther the rate\n",
      "shal be the maximam amount allowed by law, L\n",
      "\n",
      "{nthe event of a disputed invoice Client shall pay the undisputed amount within the time petiod\n",
      "Drovided and agreed by both partes mutually\n",
      "\n",
      "By Ebix. Except as may be linited by Section § ofthis Agreement, Ebix agrees to defend Client, and\n",
      "its directors, employees and agens, against claims, suits or actions arising gut ofa claim that (the use\n",
      "‘ofthe products and/or services under a Subject Agreement infinge a United States trademark patent or\n",
      "‘copyright ofa third party; oi) Ebix violated its obligations to Client under Section 7 of this\n",
      "‘Agreement. Ebix agrees to pay costs and damages (including reasonable attomeys\" fees) finally\n",
      "‘warded against Client or paid in setlement for such inffingement with respet tothe use ofthe\n",
      "Droducts and /r services, provided, Bbix is notifed promptly in writing of any suit or claim, and thet\n",
      "Client permits Ebixto defend, compromise or stl said claim of infringement and gives Ebix\n",
      "information, assistance, and authority to enable Ebi odo so. Ebix shall not be responsible for any\n",
      "compromise or settlement made without its consent,\n",
      "\n",
      "By Client. Except as may be limited by Section $ ofthis Agreement, Client agrees to defend Ebi, and\n",
      "its directors, employees and agents, agains claims, suits or actions arising out of acai () relating\n",
      "EBbix’s possession, disclosure or use of data provided by Client pursuant to Subjest Agreement\n",
      "inffinge a United States trademark, patent, copyright, or other right ofa third party of (1) Client\n",
      "Violated its obligations to Ebix under Seetion 7 ofthis Agreement. Client agrees to pay costs and\n",
      "sdamages including reasonable attorneys’ fes) finally awarded against Ebix or paid in settlement for\n",
      "\n",
      "= Master Agreement i\n",
      "\n",
      "Vile tet? ne\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "im = Image.open(\"agreement.png\")\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Character\n",
      "Recogninon\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"imageSearch.png\")\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(\"chinese.png\")\n",
    "text = pytesseract.image_to_string(im, lang = 'chi_tra')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "\n",
      "Error: the JSON object must be str, bytes or bytearray, not NoneType\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from googletrans import Translator\n",
    "\n",
    "image = Image.open(\"chinese.png\")\n",
    "text = pytesseract.image_to_string(image, lang='chi_tra+eng')\n",
    "\n",
    "print(f'Extracted Text:\\n{text}')\n",
    "translator = Translator()\n",
    "\n",
    "try:\n",
    "\n",
    "    detected_lang = translator.detect(text).lang\n",
    "    print(f'Detected Language: {detected_lang}')\n",
    "    \n",
    "    # Translate text\n",
    "    translated_text = translator.translate(text, dest='en')\n",
    "    print(f'Translated Text:\\n{translated_text.text}')\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AISHANI\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nMarianTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize translation model and tokenizer\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHelsinki-NLP/opus-mt-mul-en\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 19\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMarianTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(model_name)\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m MarianMTModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Translate text to English\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AISHANI\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\import_utils.py:1475\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1475\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\AISHANI\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\utils\\import_utils.py:1463\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1461\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nMarianTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Set up Tesseract executable path if not set automatically\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'/path/to/tesseract'\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('chinese.png')\n",
    "\n",
    "# Specify multiple languages for Tesseract\n",
    "languages = 'eng+chi_tra+chi_sim'  # Example for English, French, and German\n",
    "\n",
    "# Extract text using Tesseract\n",
    "extracted_text = pytesseract.image_to_string(image, lang=languages)\n",
    "\n",
    "# Initialize translation model and tokenizer\n",
    "model_name = 'Helsinki-NLP/opus-mt-mul-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# Translate text to English\n",
    "def translate_to_english(text):\n",
    "    translated = model.generate(**tokenizer(text, return_tensors=\"pt\", padding=True))\n",
    "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "translated_text = translate_to_english(extracted_text)\n",
    "\n",
    "# Print the extracted and translated text\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)\n",
    "print(\"\\nTranslated Text:\")\n",
    "print(translated_text[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
